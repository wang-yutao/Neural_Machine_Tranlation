{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Source Han Sans SC'\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "# 中文处理\n",
    "import langconv\n",
    "import jieba\n",
    "\n",
    "# 评价指标\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfodePkj3jEa"
   },
   "source": [
    "# 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    return pairs\n",
    "\n",
    "# 将繁体转为简体\n",
    "def simple2tradition(line):\n",
    "    line = langconv.Converter('zh-hans').convert(line)\n",
    "    return line\n",
    "\n",
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # 中文标点+数字\n",
    "    table = str.maketrans('', '', string.digits+' '+'\"')\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        \n",
    "        # 处理英文\n",
    "        line = pair[0]\n",
    "        # normalize unicode characters\n",
    "        line = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # 在单词与跟在其后的标点符号之间插入一个空格\n",
    "        line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "        line = re.sub(r'[\" \"]+', \" \", line)\n",
    "        # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格\n",
    "        line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "        line = line.rstrip().strip()\n",
    "        # convert to lowercase\n",
    "        line = line.lower()\n",
    "        # store as string\n",
    "        clean_pair.append('<start> '+line+' <end>')\n",
    "\n",
    "        # 处理中文\n",
    "        line = pair[1]\n",
    "        # 删去数字\n",
    "        line = line.translate(table)\n",
    "        # 英文标点替换\n",
    "        line = line.replace(',', '，')\n",
    "        line = line.replace('.', '。')\n",
    "        line = line.replace('!', '！')\n",
    "        line = line.replace('?', '？')\n",
    "        # 未翻译文字翻译\n",
    "        line = line.replace('Tom', '汤姆')\n",
    "        line = line.replace('tom', '汤姆')\n",
    "        line = line.replace('Mary', '玛丽')\n",
    "        line = line.replace('Facebook', '脸书')\n",
    "        line = line.replace('CD', '光盘')\n",
    "\n",
    "        line = simple2tradition(line)\n",
    "        # line = [re_print.sub('', w) for w in line]\n",
    "        # clean_pair.append(''.join(line))\n",
    "        line = jieba.cut(line)\n",
    "        clean_pair.append('<start> '+' '.join(line)+' <end>')\n",
    "\n",
    "        cleaned.append(clean_pair)\n",
    "    return np.array(cleaned)\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "    pickle.dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 unicode 文件转换为 ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_english(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    # 给句子加上开始和结束标记\n",
    "    # 以便模型知道何时开始和结束预测\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_chinese(w):\n",
    "    table = str.maketrans('', '', string.digits+' '+'\"')\n",
    "    # 删去数字、空格和引号\n",
    "    w = w.translate(table)\n",
    "    # 英文标点替换\n",
    "    w = w.replace(',', '，')\n",
    "    w = w.replace('.', '。')\n",
    "    w = w.replace('!', '！')\n",
    "    w = w.replace('?', '？')\n",
    "    # 未翻译文字翻译\n",
    "    w = w.replace('Tom', '汤姆')\n",
    "    w = w.replace('tom', '汤姆')\n",
    "    w = w.replace('Mary', '玛丽')\n",
    "    w = w.replace('Facebook', '脸书')\n",
    "    w = w.replace('CD', '光盘')\n",
    "\n",
    "    w = langconv.Converter('zh-hans').convert(w)\n",
    "    w = jieba.cut(w)\n",
    "    w = ' '.join(w)\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from the default dictionary ...\nLoading model from cache /var/folders/3v/sx4fg6vs0hx7q4vw2mcxcpp40000gn/T/jieba.cache\n<start> may i borrow this book ? <end>\nLoading model cost 0.842 seconds.\nPrefix dict has been built successfully.\n<start> 我能 藉 你 的 书 吗 ？ <end>\n"
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "cn_sentence = u\"我能藉你的書嗎？\"\n",
    "print(preprocess_english(en_sentence))\n",
    "print(preprocess_chinese(cn_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    # 读入行 以回车分割\n",
    "    doc = io.open(path, encoding='UTF-8').read()\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    # 按行处理\n",
    "    clean_en = list()\n",
    "    clean_cn = list()\n",
    "    for pair in pairs[:num_examples]:\n",
    "        clean_en.append(preprocess_english(pair[0]))\n",
    "        clean_cn.append(preprocess_chinese(pair[1]))\n",
    "    return clean_en, clean_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n<start> 如果 一个 人 在 成人 前 没有 机会 习得 目标语言 ， 他 对 该 语言 的 认识 达到 母语 者 程度 的 机会 是 相当 小 的 。 <end>\n"
    }
   ],
   "source": [
    "path_to_file = 'cmn.txt'\n",
    "clean_en, clean_cn = create_dataset(path_to_file, None)\n",
    "print(clean_en[-1])\n",
    "print(clean_cn[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[<start> hi . <end>] => [<start> 嗨 。 <end>]\n[<start> hi . <end>] => [<start> 你好 。 <end>]\n[<start> run . <end>] => [<start> 你 用 跑 的 。 <end>]\n[<start> wait ! <end>] => [<start> 等等 ！ <end>]\n[<start> wait ! <end>] => [<start> 等 一下 ！ <end>]\n[<start> hello ! <end>] => [<start> 你好 。 <end>]\n[<start> i try . <end>] => [<start> 让 我 来 。 <end>]\n[<start> i won ! <end>] => [<start> 我 赢 了 。 <end>]\n[<start> oh no ! <end>] => [<start> 不会 吧 。 <end>]\n[<start> cheers ! <end>] => [<start> 干杯 ！ <end>]\n[<start> got it ? <end>] => [<start> 你 懂 了 吗 ？ <end>]\n[<start> he ran . <end>] => [<start> 他 跑 了 。 <end>]\n[<start> hop in . <end>] => [<start> 跳进来 。 <end>]\n[<start> i quit . <end>] => [<start> 我 退出 。 <end>]\n[<start> i m ok . <end>] => [<start> 我 没事 。 <end>]\n[<start> listen . <end>] => [<start> 听 着 。 <end>]\n[<start> no way ! <end>] => [<start> 不 可能 ！ <end>]\n[<start> no way ! <end>] => [<start> 没门 ！ <end>]\n[<start> really ? <end>] => [<start> 你 确定 ？ <end>]\n[<start> try it . <end>] => [<start> 试试 吧 。 <end>]\n[<start> we try . <end>] => [<start> 我们 来 试试 。 <end>]\n[<start> why me ? <end>] => [<start> 为什么 是 我 ？ <end>]\n[<start> ask tom . <end>] => [<start> 去 问 汤姆 。 <end>]\n[<start> awesome ! <end>] => [<start> 好棒 ！ <end>]\n[<start> be calm . <end>] => [<start> 冷静 点 。 <end>]\n[<start> be fair . <end>] => [<start> 公平 点 。 <end>]\n[<start> be kind . <end>] => [<start> 友善 点 。 <end>]\n[<start> be nice . <end>] => [<start> 和 气点 。 <end>]\n[<start> be nice . <end>] => [<start> 友善 点 。 <end>]\n[<start> call me . <end>] => [<start> 联系 我 。 <end>]\n[<start> call us . <end>] => [<start> 联系 我们 。 <end>]\n[<start> come in . <end>] => [<start> 进来 。 <end>]\n[<start> get tom . <end>] => [<start> 找到 汤姆 。 <end>]\n[<start> get out ! <end>] => [<start> 滚出去 ！ <end>]\n[<start> get out ! <end>] => [<start> 出去 ！ <end>]\n[<start> go away ! <end>] => [<start> 走开 ！ <end>]\n[<start> go away ! <end>] => [<start> 滚 ！ <end>]\n[<start> go away . <end>] => [<start> 走开 ！ <end>]\n[<start> go home . <end>] => [<start> 回家吧 。 <end>]\n[<start> goodbye ! <end>] => [<start> 再见 ！ <end>]\n[<start> goodbye ! <end>] => [<start> 告辞 ！ <end>]\n[<start> hang on ! <end>] => [<start> 坚持 。 <end>]\n[<start> hang on ! <end>] => [<start> 等 一下 ！ <end>]\n[<start> hang on . <end>] => [<start> 坚持 。 <end>]\n[<start> he came . <end>] => [<start> 他来 了 。 <end>]\n[<start> he runs . <end>] => [<start> 他 跑 。 <end>]\n[<start> help me . <end>] => [<start> 帮 我 一下 。 <end>]\n[<start> help us . <end>] => [<start> 帮帮 我们 吧 ！ <end>]\n[<start> hold on . <end>] => [<start> 坚持 。 <end>]\n[<start> hug tom . <end>] => [<start> 抱抱 汤姆 ！ <end>]\n[<start> hug tom . <end>] => [<start> 请 抱紧 汤姆 。 <end>]\n[<start> i agree . <end>] => [<start> 我 同意 。 <end>]\n[<start> i m ill . <end>] => [<start> 我 生病 了 。 <end>]\n[<start> i m old . <end>] => [<start> 我 老 了 。 <end>]\n[<start> i m wet . <end>] => [<start> 我 湿 了 。 <end>]\n[<start> it s ok . <end>] => [<start> 没关系 。 <end>]\n[<start> it s me . <end>] => [<start> 是 我 。 <end>]\n[<start> join us . <end>] => [<start> 来 加入 我们 吧 。 <end>]\n[<start> keep it . <end>] => [<start> 留着 吧 。 <end>]\n[<start> kiss me . <end>] => [<start> 吻 我 。 <end>]\n[<start> perfect ! <end>] => [<start> 完美 ！ <end>]\n[<start> see you . <end>] => [<start> 再见 ！ <end>]\n[<start> shut up ! <end>] => [<start> 闭嘴 ！ <end>]\n[<start> skip it . <end>] => [<start> 不管 它 。 <end>]\n[<start> take it . <end>] => [<start> 拿走 吧 。 <end>]\n[<start> wake up ! <end>] => [<start> 醒醒 ！ <end>]\n[<start> wash up . <end>] => [<start> 去 清洗 一下 。 <end>]\n[<start> we know . <end>] => [<start> 我们 知道 。 <end>]\n[<start> welcome . <end>] => [<start> 欢迎 。 <end>]\n[<start> who won ? <end>] => [<start> 谁 赢 了 ？ <end>]\n[<start> why not ? <end>] => [<start> 为什么 不 ？ <end>]\n[<start> you run . <end>] => [<start> 你 跑 。 <end>]\n[<start> back off . <end>] => [<start> 往 后退 点 。 <end>]\n[<start> be still . <end>] => [<start> 静静的 ， 别动 。 <end>]\n[<start> beats me . <end>] => [<start> 我 一无所知 。 <end>]\n[<start> cuff him . <end>] => [<start> 把 他 铐 上 。 <end>]\n[<start> drive on . <end>] => [<start> 往前 开 。 <end>]\n[<start> get away ! <end>] => [<start> 走开 ！ <end>]\n[<start> get away ! <end>] => [<start> 滚 ！ <end>]\n[<start> get down ! <end>] => [<start> 趴下 ！ <end>]\n[<start> get lost ! <end>] => [<start> 滚 ！ <end>]\n[<start> get real . <end>] => [<start> 醒醒 吧 。 <end>]\n[<start> good job ! <end>] => [<start> 做得好 ！ <end>]\n[<start> good job ! <end>] => [<start> 干 的 好 ！ <end>]\n[<start> grab tom . <end>] => [<start> 抓住 汤姆 。 <end>]\n[<start> grab him . <end>] => [<start> 抓住 他 。 <end>]\n[<start> have fun . <end>] => [<start> 玩得 开心 。 <end>]\n[<start> he tries . <end>] => [<start> 他来 试试 。 <end>]\n[<start> how cute ! <end>] => [<start> 多 可爱 啊 ！ <end>]\n[<start> humor me . <end>] => [<start> 你 就 随 了 我 的 意 吧 。 <end>]\n[<start> hurry up . <end>] => [<start> 赶快 ！ <end>]\n[<start> hurry up . <end>] => [<start> 快点 ！ <end>]\n[<start> hurry up . <end>] => [<start> 快点 。 <end>]\n[<start> i forgot . <end>] => [<start> 我 忘 了 。 <end>]\n[<start> i resign . <end>] => [<start> 我 放弃 。 <end>]\n[<start> i ll pay . <end>] => [<start> 我来 付钱 。 <end>]\n[<start> i m busy . <end>] => [<start> 我 很 忙 。 <end>]\n[<start> i m cold . <end>] => [<start> 我 冷 。 <end>]\n[<start> i m fine . <end>] => [<start> 我 很 好 。 <end>]\n[<start> i m full . <end>] => [<start> 我 吃饱 了 。 <end>]\n"
    }
   ],
   "source": [
    "# spot check\n",
    "for i in range(100):\n",
    "    print('[%s] => [%s]' % (clean_en[i], clean_cn[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(num_examples=None):\n",
    "    # 创建清理过的输入输出对\n",
    "    targ_lang = clean_en\n",
    "    inp_lang = clean_cn\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "English Vocabulary Size: 6235\nEnglish Max Length: 38\nChinese Vocabulary Size: 10768\nChinese Max Length: 30\n"
    }
   ],
   "source": [
    "# 尝试实验不同大小的数据集\n",
    "# num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n",
    "\n",
    "# 计算目标张量的最大长度 （max_length）\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "print('English Vocabulary Size: %d' % len(targ_lang.word_index))\n",
    "print('English Max Length: %d' % max_length_targ)\n",
    "\n",
    "print('Chinese Vocabulary Size: %d' % len(inp_lang.word_index))\n",
    "print('Chinese Max Length: %d' % max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "17660 17660 4415 4415\n"
    }
   ],
   "source": [
    "# 采用 80 - 20 的比例切分训练集和验证集\n",
    "input_tensor_train, input_tensor_test, target_tensor_train, target_tensor_test = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 显示长度\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_test), len(target_tensor_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "def save_tensor(sentences, filename):\n",
    "    pickle.dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Saved: input_tensor_train.pkl\nSaved: target_tensor_train.pkl\nSaved: input_tensor_test.pkl\nSaved: target_tensor_test.pkl\n"
    }
   ],
   "source": [
    "save_tensor(input_tensor_train, 'input_tensor_train.pkl')\n",
    "save_tensor(target_tensor_train, 'target_tensor_train.pkl')\n",
    "save_tensor(input_tensor_test, 'input_tensor_test.pkl')\n",
    "save_tensor(target_tensor_test, 'target_tensor_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input Language; index to word mapping\n1 ----> <start>\n8 ----> 他\n436 ----> 似乎\n53 ----> 不是\n216 ----> 美国\n35 ----> 人\n3 ----> 。\n2 ----> <end>\n\nTarget Language; index to word mapping\n1 ----> <start>\n11 ----> he\n108 ----> doesn\n12 ----> t\n624 ----> seem\n6 ----> to\n38 ----> be\n64 ----> an\n731 ----> american\n3 ----> .\n2 ----> <end>\n"
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "# 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 512\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc6-NK1GtWQt"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorShape([64, 30]), TensorShape([64, 38]))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## 编写编码器 （encoder） 和解码器 （decoder） 模型\n",
    "\n",
    "实现一个基于注意力的编码器 - 解码器模型。关于这种模型，你可以阅读 TensorFlow 的 [神经机器翻译 (序列到序列) 教程](https://github.com/tensorflow/nmt)。本示例采用一组更新的 API。此笔记本实现了上述序列到序列教程中的 [注意力方程式](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism)。下图显示了注意力机制为每个输入单词分配一个权重，然后解码器将这个权重用于预测句子中的下一个单词。下图和公式是 [Luong 的论文](https://arxiv.org/abs/1508.04025v5)中注意力机制的一个例子。\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "输入经过编码器模型，编码器模型为我们提供形状为 *(批大小，最大长度，隐藏层大小)* 的编码器输出和形状为 *(批大小，隐藏层大小)* 的编码器隐藏层状态。\n",
    "\n",
    "下面是所实现的方程式：\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "本教程的编码器采用 [Bahdanau 注意力](https://arxiv.org/pdf/1409.0473.pdf)。在用简化形式编写之前，让我们先决定符号：\n",
    "\n",
    "* FC = 完全连接（密集）层\n",
    "* EO = 编码器输出\n",
    "* H = 隐藏层状态\n",
    "* X = 解码器输入\n",
    "\n",
    "以及伪代码：\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`。 Softmax 默认被应用于最后一个轴，但是这里我们想将它应用于 *第一个轴*, 因为分数 （score） 的形状是 *(批大小，最大长度，隐藏层大小)*。最大长度 （`max_length`） 是我们的输入的长度。因为我们想为每个输入分配一个权重，所以 softmax 应该用在这个轴上。\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`。选择第一个轴的原因同上。\n",
    "* `embedding output` = 解码器输入 X 通过一个嵌入层。\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* 此合并后的向量随后被传送到 GRU\n",
    "\n",
    "每个步骤中所有向量的形状已在代码的注释中阐明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Encoder output shape: (batch size, sequence length, units) (64, 30, 1024)\nEncoder Hidden state shape: (batch size, units) (64, 1024)\n"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# 样本输入\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # 隐藏层的形状 == （批大小，隐藏层大小）\n",
    "    # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
    "    # 这样做是为了执行加法以计算分数  \n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # 分数的形状 == （批大小，最大长度，1）\n",
    "    # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
    "    # 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k534zTHiDjQU"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Attention result shape: (batch size, units) (64, 1024)\nAttention weights shape: (batch_size, sequence_length, 1) (64, 30, 1)\n"
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # 用于注意力\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # 将合并后的向量传送到 GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # 输出的形状 == （批大小 * 1，隐藏层大小）\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # 输出的形状 == （批大小，vocab）\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5UY8wko3jFp"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Decoder output shape: (batch_size, vocab size) (64, 6236)\n"
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制结构图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = tf.keras.layers.Input(shape=(max_length_inp,))\n",
    "\n",
    "# enc_hidden = encoder.initialize_hidden_state()\n",
    "# enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "# enc_model = tf.keras.Model(inp, [enc_output, enc_hidden])\n",
    "\n",
    "# tf.keras.utils.plot_model(enc_model, to_file='enc_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_output = tf.keras.layers.Input(shape=(30, 1024))\n",
    "# enc_hidden = tf.keras.layers.Input(shape=(1024,))\n",
    "\n",
    "# tar = tf.keras.layers.Input(shape=(max_length_targ,))\n",
    "\n",
    "# dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "# dec_hidden = enc_hidden\n",
    "\n",
    "# outputs = []\n",
    "# # 教师强制 - 将目标词作为下一个输入\n",
    "# for t in range(1, tar.shape[1]):\n",
    "#     # 将编码器输出 （enc_output） 传送至解码器\n",
    "#     predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "#     outputs.append(predictions)\n",
    "#     # 使用教师强制\n",
    "#     dec_input = tf.expand_dims(tar[:, t], 1)\n",
    "\n",
    "# dec_model = tf.keras.Model([enc_output, enc_hidden, tar], outputs)\n",
    "# tf.keras.utils.plot_model(dec_model, to_file='dec_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## 定义优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## 检查点（基于对象保存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpObfY22IddU"
   },
   "source": [
    "## 训练\n",
    "\n",
    "1. 将 *输入* 传送至 *编码器*，编码器返回 *编码器输出* 和 *编码器隐藏层状态*。\n",
    "2. 将编码器输出、编码器隐藏层状态和解码器输入（即 *开始标记*）传送至解码器。\n",
    "3. 解码器返回 *预测* 和 *解码器隐藏层状态*。\n",
    "4. 解码器隐藏层状态被传送回模型，预测被用于计算损失。\n",
    "5. 使用 *教师强制 （teacher forcing）* 决定解码器的下一个输入。\n",
    "6. *教师强制* 是将 *目标词* 作为 *下一个输入* 传送至解码器的技术。\n",
    "7. 最后一步是计算梯度，并将其应用于优化器和反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 教师强制 - 将目标词作为下一个输入\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # 将编码器输出 （enc_output） 传送至解码器\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 使用教师强制\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddefjBMa3jF0"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2d5e5a7871c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    546\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    547\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 548\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m                 ))\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3v/sx4fg6vs0hx7q4vw2mcxcpp40000gn/T/tmpb0_swrpu.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(inp, targ, enc_hidden)\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dec_input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dec_hidden'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m       \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[0;34m(protected_iter)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0moriginal_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3v/sx4fg6vs0hx7q4vw2mcxcpp40000gn/T/tmpb0_swrpu.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                         \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dec_input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dec_hidden'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3v/sx4fg6vs0hx7q4vw2mcxcpp40000gn/T/tmpvxnsqw6j.py\u001b[0m in \u001b[0;36mtf__loss_function\u001b[0;34m(real, pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mincompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \"\"\"\n\u001b[0;32m-> 1554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3261\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m   3262\u001b[0m         \u001b[0;34m\"Equal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m                  name=name)\n\u001b[0m\u001b[1;32m   3264\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    468\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m               \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m               preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    298\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    299\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m   if dtype is not None and (not hasattr(dtype, \"base_dtype\") or\n\u001b[0;32m--> 485\u001b[0;31m                             dtype.base_dtype != numpy_dtype.base_dtype):\n\u001b[0m\u001b[1;32m    486\u001b[0m     raise TypeError(\"Incompatible types: %s vs. %s. Value is %s\" %\n\u001b[1;32m    487\u001b[0m                     (dtype, nparray.dtype, values))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mbase_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbase_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m\"\"\"Returns a non-reference `DType` based on this `DType`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m_is_ref_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m\"\"\"Returns `True` if this `DType` represents a reference type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "  # 每 2 个周期（epoch），保存（检查点）一次模型\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  loss_list.append(total_loss / steps_per_epoch)\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## 翻译\n",
    "\n",
    "* 评估函数类似于训练循环，不同之处在于在这里我们不使用 *教师强制*。每个时间步的解码器输入是其先前的预测、隐藏层状态和编码器输出。\n",
    "* 当模型预测 *结束标记* 时停止预测。\n",
    "* 存储 *每个时间步的注意力权重*。\n",
    "\n",
    "请注意：对于一个输入，编码器输出仅计算一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_chinese(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 存储注意力权重以便后面制图\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # 预测的 ID 被输送回模型\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5hQWlbN3jGF"
   },
   "outputs": [],
   "source": [
    "# 注意力权重制图函数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## 恢复最新的检查点并验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJpT9D5_OgP6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a3d175dd0>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# 恢复检查点目录 （checkpoint_dir） 中最新的检查点\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "checkpoint.restore(os.path.join(checkpoint_dir, \"ckpt-10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "inp_lang.word_index['。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrAM0FDomq3E"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input: <start> 我 是 一名 学生 。 <end>\nPredicted translation: i m a student . <end> \n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"613.822813pt\" version=\"1.1\" viewBox=\"0 0 615.010625 613.822813\" width=\"615.010625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 613.822813 \nL 615.010625 613.822813 \nL 615.010625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 64.210625 603.122813 \nL 607.810625 603.122813 \nL 607.810625 59.522812 \nL 64.210625 59.522812 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pd6d7e630b6)\">\n    <image height=\"544\" id=\"image3e0c6502da\" transform=\"scale(1 -1)translate(0 -544)\" width=\"544\" x=\"64.210625\" xlink:href=\"data:image/png;base64,\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\" y=\"-59.122813\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9b3d19eb78\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.039196\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 -3.5 \n\" id=\"medb9a32a9d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.039196\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- &lt;start&gt; -->\n      <defs>\n       <path d=\"M 51.09375 15 \nL 51.09375 22.203125 \nL 27 31.203125 \nL 12.09375 36.796875 \nL 12.09375 37.203125 \nL 27 42.90625 \nL 51.09375 51.796875 \nL 51.09375 59 \nL 3.796875 40.40625 \nL 3.796875 33.59375 \nz\n\" id=\"SourceHanSansSC-Normal-60\"/>\n       <path d=\"M 23.296875 -1.296875 \nC 35.796875 -1.296875 42.59375 5.90625 42.59375 14.5 \nC 42.59375 24.796875 33.796875 27.90625 25.90625 31 \nC 19.703125 33.203125 14.09375 35.296875 14.09375 40.703125 \nC 14.09375 45.09375 17.40625 48.90625 24.59375 48.90625 \nC 29.5 48.90625 33.296875 46.796875 37 44.09375 \nL 41 49.40625 \nC 36.90625 52.703125 31.09375 55.40625 24.59375 55.40625 \nC 12.90625 55.40625 6.203125 48.703125 6.203125 40.296875 \nC 6.203125 31.09375 14.5 27.5 22.203125 24.703125 \nC 28.296875 22.5 34.796875 19.90625 34.796875 14.09375 \nC 34.796875 9.09375 31.09375 5.09375 23.59375 5.09375 \nC 16.796875 5.09375 12 7.796875 7.296875 11.59375 \nL 3.203125 6.09375 \nC 8.296875 1.90625 15.59375 -1.296875 23.296875 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-115\"/>\n       <path d=\"M 25.90625 -1.296875 \nC 28.90625 -1.296875 32.5 -0.296875 35.5 0.703125 \nL 33.90625 6.90625 \nC 32.09375 6.09375 29.59375 5.40625 27.59375 5.40625 \nC 21.09375 5.40625 19.09375 9.40625 19.09375 16 \nL 19.09375 47.296875 \nL 34 47.296875 \nL 34 54 \nL 19.09375 54 \nL 19.09375 69.296875 \nL 12.296875 69.296875 \nL 11.296875 54 \nL 2.796875 53.5 \nL 2.796875 47.296875 \nL 11 47.296875 \nL 11 16.296875 \nC 11 5.796875 14.59375 -1.296875 25.90625 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-116\"/>\n       <path d=\"M 21.703125 -1.296875 \nC 28.5 -1.296875 34.703125 2.203125 39.90625 6.59375 \nL 40.203125 6.59375 \nL 40.90625 0 \nL 47.59375 0 \nL 47.59375 33.5 \nC 47.59375 46.5 42.40625 55.40625 29.296875 55.40625 \nC 20.59375 55.40625 13 51.40625 8.296875 48.296875 \nL 11.59375 42.59375 \nC 15.703125 45.5 21.5 48.59375 28 48.59375 \nC 37.296875 48.59375 39.59375 41.40625 39.5 34.09375 \nC 16.296875 31.5 6 25.703125 6 13.90625 \nC 6 4.09375 12.796875 -1.296875 21.703125 -1.296875 \nz\nM 23.90625 5.296875 \nC 18.40625 5.296875 13.90625 7.90625 13.90625 14.40625 \nC 13.90625 21.796875 20.40625 26.40625 39.5 28.59375 \nL 39.5 12.796875 \nC 34 7.90625 29.40625 5.296875 23.90625 5.296875 \nz\n\" id=\"SourceHanSansSC-Normal-97\"/>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 35.203125 \nC 21.296875 44.59375 26.90625 48 31.5 48 \nC 33.59375 48 34.796875 47.703125 36.59375 47.09375 \nL 38.203125 54.203125 \nC 36.40625 55.09375 34.796875 55.40625 32.5 55.40625 \nC 26.40625 55.40625 20.90625 50.90625 17.203125 44.09375 \nL 16.90625 44.09375 \nL 16.09375 54 \nL 9.5 54 \nz\n\" id=\"SourceHanSansSC-Normal-114\"/>\n       <path d=\"M 3.796875 15 \nL 51.09375 33.59375 \nL 51.09375 40.40625 \nL 3.796875 59 \nL 3.796875 51.796875 \nL 27.90625 42.90625 \nL 42.796875 37.203125 \nL 42.796875 36.796875 \nL 27.90625 31.203125 \nL 3.796875 22.203125 \nz\n\" id=\"SourceHanSansSC-Normal-62\"/>\n      </defs>\n      <g transform=\"translate(106.98654 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-60\"/>\n       <use x=\"54.899994\" xlink:href=\"#SourceHanSansSC-Normal-115\"/>\n       <use x=\"101.199982\" xlink:href=\"#SourceHanSansSC-Normal-116\"/>\n       <use x=\"138.099976\" xlink:href=\"#SourceHanSansSC-Normal-97\"/>\n       <use x=\"193.999969\" xlink:href=\"#SourceHanSansSC-Normal-114\"/>\n       <use x=\"231.899963\" xlink:href=\"#SourceHanSansSC-Normal-116\"/>\n       <use x=\"268.799957\" xlink:href=\"#SourceHanSansSC-Normal-62\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.696339\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.696339\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 我 -->\n      <defs>\n       <path d=\"M 91.59375 64.203125 \nC 88.203125 68.796875 81.203125 75.90625 75.296875 80.796875 \nL 70.203125 77.40625 \nC 76.203125 72.203125 83 65 86.203125 60.296875 \nz\nM 83.296875 42.796875 \nC 79.796875 36 75.09375 29.59375 69.5 23.59375 \nC 67.703125 30.59375 66.296875 38.59375 65.203125 47.59375 \nL 94.203125 47.59375 \nL 94.203125 53.90625 \nL 64.5 53.90625 \nC 63.59375 62.90625 63.203125 72.5 63.203125 82.703125 \nL 56.296875 82.703125 \nC 56.40625 72.796875 56.90625 63 57.703125 53.90625 \nL 34.296875 53.90625 \nL 34.296875 72.09375 \nC 40.5 73.5 46.203125 75.09375 51 76.703125 \nL 46.203125 82.203125 \nC 36.90625 78.703125 20.59375 75.203125 6.703125 73 \nC 7.5 71.40625 8.5 69.09375 8.796875 67.5 \nC 14.90625 68.40625 21.296875 69.5 27.703125 70.796875 \nL 27.703125 53.90625 \nL 5.90625 53.90625 \nL 5.90625 47.59375 \nL 27.703125 47.59375 \nL 27.703125 29.40625 \nC 18.90625 27.40625 10.703125 25.703125 4.59375 24.59375 \nL 6.5 17.90625 \nC 12.59375 19.296875 20 20.90625 27.703125 22.796875 \nL 27.703125 1.296875 \nC 27.703125 -0.5 27.09375 -1 25.296875 -1 \nC 23.59375 -1.09375 17.703125 -1.203125 11.203125 -1 \nC 12.203125 -2.90625 13.40625 -5.796875 13.703125 -7.703125 \nC 21.90625 -7.796875 27.09375 -7.5 30.203125 -6.40625 \nC 33.09375 -5.296875 34.296875 -3.296875 34.296875 1.296875 \nL 34.296875 24.40625 \nL 53 28.796875 \nL 52.5 34.796875 \nC 46.40625 33.40625 40.296875 32 34.296875 30.703125 \nL 34.296875 47.59375 \nL 58.40625 47.59375 \nC 59.703125 36.5 61.59375 26.5 64 18.09375 \nC 56.796875 11.40625 48.59375 5.703125 40.09375 1.5 \nC 41.703125 0.09375 43.703125 -2.09375 44.796875 -3.796875 \nC 52.296875 0.296875 59.703125 5.5 66.296875 11.296875 \nC 70.90625 -0.59375 77.09375 -7.90625 85.09375 -7.90625 \nC 92.296875 -7.90625 94.796875 -3 96 13.40625 \nC 94.203125 14.09375 91.796875 15.59375 90.40625 16.90625 \nC 89.796875 4 88.5 -1.203125 85.703125 -1.203125 \nC 80.296875 -1.203125 75.5 5.40625 71.703125 16.5 \nC 78.703125 23.703125 84.703125 31.796875 89.203125 40.296875 \nz\n\" id=\"SourceHanSansSC-Normal-25105\"/>\n      </defs>\n      <g transform=\"translate(184.643683 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-25105\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"258.353482\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"258.353482\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 是 -->\n      <defs>\n       <path d=\"M 76.09375 65.5 \nL 23.296875 65.5 \nL 23.296875 74.09375 \nL 76.09375 74.09375 \nz\nM 76.09375 51.796875 \nL 23.296875 51.796875 \nL 23.296875 60.59375 \nL 76.09375 60.59375 \nz\nM 82.796875 79.296875 \nL 16.796875 79.296875 \nL 16.796875 46.703125 \nL 82.796875 46.703125 \nz\nM 54.09375 15.703125 \nL 87.5 15.703125 \nL 87.5 21.703125 \nL 54.09375 21.703125 \nL 54.09375 33.5 \nL 94 33.5 \nL 94 39.5 \nL 6.203125 39.5 \nL 6.203125 33.5 \nL 47.40625 33.5 \nL 47.40625 2.59375 \nC 38.40625 4.796875 31.796875 9.59375 27.90625 19 \nC 28.90625 22.203125 29.703125 25.5 30.40625 29.09375 \nL 23.796875 30.09375 \nC 21.09375 15.203125 14.59375 3.90625 4.09375 -3 \nC 5.59375 -4 8.203125 -6.5 9.203125 -7.703125 \nC 15.796875 -2.703125 21.09375 3.703125 25 11.796875 \nC 33 -2.296875 45.703125 -5.5 66.203125 -5.5 \nL 93.296875 -5.5 \nC 93.703125 -3.59375 94.796875 -0.703125 95.703125 0.90625 \nC 91 0.796875 69.90625 0.703125 66.40625 0.796875 \nC 62 0.796875 57.90625 1 54.09375 1.40625 \nz\n\" id=\"SourceHanSansSC-Normal-26159\"/>\n      </defs>\n      <g transform=\"translate(262.300826 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-26159\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"336.010625\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"336.010625\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 一名 -->\n      <defs>\n       <path d=\"M 4.796875 42.59375 \nL 4.796875 35.40625 \nL 95.59375 35.40625 \nL 95.59375 42.59375 \nz\n\" id=\"SourceHanSansSC-Normal-19968\"/>\n       <path d=\"M 32.203125 4 \nL 32.203125 27.5 \nL 77.796875 27.5 \nL 77.796875 4 \nz\nM 84.5 33.59375 \nL 43.40625 33.59375 \nC 60.5 42.40625 75.5 54.90625 84 71.09375 \nL 79.59375 73.90625 \nL 78.40625 73.5 \nL 42 73.5 \nC 44.5 76.40625 46.703125 79.40625 48.59375 82.296875 \nL 41.203125 83.796875 \nC 35.296875 74.296875 23.796875 63 7.703125 55.203125 \nC 9.09375 54.09375 11.296875 51.703125 12.296875 50.203125 \nC 21.796875 55.203125 29.796875 61.09375 36.296875 67.40625 \nL 74.203125 67.40625 \nC 68.09375 58.296875 59.203125 50.5 48.90625 44.203125 \nC 44.296875 48.296875 37.59375 53.40625 32.09375 57.09375 \nL 27.09375 53.296875 \nC 32.296875 49.703125 38.5 44.796875 42.90625 40.703125 \nC 31 34.203125 17.796875 29.59375 5.296875 27 \nC 6.59375 25.5 8.203125 22.703125 8.703125 20.90625 \nC 14.296875 22.203125 19.90625 23.90625 25.59375 25.90625 \nL 25.59375 -7.5 \nL 32.203125 -7.5 \nL 32.203125 -2.09375 \nL 77.796875 -2.09375 \nL 77.796875 -7.5 \nL 84.5 -7.5 \nz\n\" id=\"SourceHanSansSC-Normal-21517\"/>\n      </defs>\n      <g transform=\"translate(339.957969 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-19968\"/>\n       <use x=\"99.999985\" xlink:href=\"#SourceHanSansSC-Normal-21517\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.667768\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.667768\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 学生 -->\n      <defs>\n       <path d=\"M 14.796875 60.796875 \nL 85.796875 60.796875 \nL 85.796875 47.5 \nL 92.296875 47.5 \nL 92.296875 66.796875 \nL 75.5 66.796875 \nC 78.796875 70.90625 82.59375 75.90625 85.59375 80.5 \nL 79 82.90625 \nC 76.5 78.09375 72.203125 71.40625 68.5 66.796875 \nL 51.796875 66.796875 \nL 56.703125 68.796875 \nC 55.5 73.09375 52 79.5 48.5 84.296875 \nL 42.703125 82.203125 \nC 45.90625 77.5 49.203125 71.09375 50.5 66.796875 \nL 27.59375 66.796875 \nL 31.40625 68.796875 \nC 29.703125 72.703125 25.59375 78.40625 21.796875 82.5 \nL 16.296875 80 \nC 19.59375 76 23.296875 70.703125 25.203125 66.796875 \nL 8.5 66.796875 \nL 8.5 47.5 \nL 14.796875 47.5 \nz\nM 94.203125 27.296875 \nL 53.203125 27.296875 \nL 53.203125 31.796875 \nC 62.203125 35.703125 71.796875 41.296875 78.296875 47.203125 \nL 73.90625 50.40625 \nL 72.5 50.09375 \nL 22.796875 50.09375 \nL 22.796875 44.09375 \nL 64.90625 44.09375 \nC 59.59375 40.5 52.703125 36.90625 46.5 34.703125 \nL 46.5 27.296875 \nL 6.296875 27.296875 \nL 6.296875 21.09375 \nL 46.5 21.09375 \nL 46.5 0.90625 \nC 46.5 -0.5 46 -1 43.90625 -1.09375 \nC 42 -1.296875 35.296875 -1.296875 27.5 -1 \nC 28.5 -2.90625 29.796875 -5.5 30.296875 -7.5 \nC 39.5 -7.5 45.09375 -7.40625 48.59375 -6.296875 \nC 52 -5.296875 53.203125 -3.40625 53.203125 0.90625 \nL 53.203125 21.09375 \nL 94.203125 21.09375 \nz\n\" id=\"SourceHanSansSC-Normal-23398\"/>\n       <path d=\"M 53.59375 2.09375 \nL 53.59375 28.5 \nL 86.203125 28.5 \nL 86.203125 34.90625 \nL 53.59375 34.90625 \nL 53.59375 57.5 \nL 89.796875 57.5 \nL 89.796875 64 \nL 53.59375 64 \nL 53.59375 83.5 \nL 46.703125 83.5 \nL 46.703125 64 \nL 25.5 64 \nC 27.703125 69.203125 29.59375 74.796875 31.203125 80.40625 \nL 24.59375 81.796875 \nC 20.703125 67.5 14.296875 53.703125 6 44.796875 \nC 7.703125 43.90625 10.703125 41.90625 12 40.796875 \nC 15.796875 45.40625 19.5 51 22.59375 57.5 \nL 46.703125 57.5 \nL 46.703125 34.90625 \nL 16.59375 34.90625 \nL 16.59375 28.5 \nL 46.703125 28.5 \nL 46.703125 2.09375 \nL 5.796875 2.09375 \nL 5.796875 -4.40625 \nL 94.5 -4.40625 \nL 94.5 2.09375 \nz\n\" id=\"SourceHanSansSC-Normal-29983\"/>\n      </defs>\n      <g transform=\"translate(417.615112 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-23398\"/>\n       <use x=\"99.999985\" xlink:href=\"#SourceHanSansSC-Normal-29983\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"491.324911\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"491.324911\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 。 -->\n      <defs>\n       <path d=\"M 19.40625 24.296875 \nC 11.203125 24.296875 4.40625 17.59375 4.40625 9.296875 \nC 4.40625 0.90625 11.203125 -5.796875 19.40625 -5.796875 \nC 27.796875 -5.796875 34.5 0.90625 34.5 9.296875 \nC 34.5 17.59375 27.796875 24.296875 19.40625 24.296875 \nz\nM 19.40625 -1.09375 \nC 13.796875 -1.09375 9.09375 3.5 9.09375 9.296875 \nC 9.09375 14.90625 13.796875 19.59375 19.40625 19.59375 \nC 25.203125 19.59375 29.796875 14.90625 29.796875 9.296875 \nC 29.796875 3.5 25.203125 -1.09375 19.40625 -1.09375 \nz\n\" id=\"SourceHanSansSC-Normal-12290\"/>\n      </defs>\n      <g transform=\"translate(495.272254 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-12290\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"568.982054\" xlink:href=\"#m9b3d19eb78\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"568.982054\" xlink:href=\"#medb9a32a9d\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- &lt;end&gt; -->\n      <defs>\n       <path d=\"M 30.90625 -1.296875 \nC 38.40625 -1.296875 43.90625 1.203125 48.59375 4.203125 \nL 45.59375 9.59375 \nC 41.59375 6.90625 37.203125 5.203125 31.90625 5.203125 \nC 21.09375 5.203125 13.90625 13.203125 13.40625 25.203125 \nL 50.296875 25.203125 \nC 50.59375 26.5 50.703125 28.296875 50.703125 30.09375 \nC 50.703125 45.703125 42.90625 55.40625 29.40625 55.40625 \nC 17 55.40625 5.296875 44.5 5.296875 27 \nC 5.296875 9.203125 16.703125 -1.296875 30.90625 -1.296875 \nz\nM 13.296875 31.203125 \nC 14.40625 42.296875 21.5 48.796875 29.5 48.796875 \nC 38.296875 48.796875 43.5 42.703125 43.5 31.203125 \nz\n\" id=\"SourceHanSansSC-Normal-101\"/>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 39.5 \nC 23.203125 45.296875 27.296875 48.296875 33 48.296875 \nC 40.5 48.296875 43.703125 43.703125 43.703125 33.296875 \nL 43.703125 0 \nL 51.90625 0 \nL 51.90625 34.296875 \nC 51.90625 48.09375 46.703125 55.40625 35.40625 55.40625 \nC 28 55.40625 22.40625 51.203125 17.203125 46.09375 \nL 16.90625 46.09375 \nL 16.09375 54 \nL 9.5 54 \nz\n\" id=\"SourceHanSansSC-Normal-110\"/>\n       <path d=\"M 27.703125 -1.296875 \nC 34.296875 -1.296875 40.09375 2.203125 44.40625 6.5 \nL 44.703125 6.5 \nL 45.40625 0 \nL 52.09375 0 \nL 52.09375 79.59375 \nL 44 79.59375 \nL 44 58.40625 \nL 44.40625 49 \nC 39.5 53 35.296875 55.40625 28.90625 55.40625 \nC 16.5 55.40625 5.40625 44.40625 5.40625 27 \nC 5.40625 8.90625 14.09375 -1.296875 27.703125 -1.296875 \nz\nM 29.40625 5.59375 \nC 19.5 5.59375 13.90625 13.703125 13.90625 27 \nC 13.90625 39.59375 21 48.5 30.203125 48.5 \nC 34.90625 48.5 39.09375 46.796875 44 42.5 \nL 44 13.296875 \nC 39.203125 8.203125 34.59375 5.59375 29.40625 5.59375 \nz\n\" id=\"SourceHanSansSC-Normal-100\"/>\n      </defs>\n      <g transform=\"translate(572.929397 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-60\"/>\n       <use x=\"54.899994\" xlink:href=\"#SourceHanSansSC-Normal-101\"/>\n       <use x=\"109.799988\" xlink:href=\"#SourceHanSansSC-Normal-110\"/>\n       <use x=\"170.299973\" xlink:href=\"#SourceHanSansSC-Normal-100\"/>\n       <use x=\"231.799957\" xlink:href=\"#SourceHanSansSC-Normal-62\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m6d6a6195dd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"98.351384\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- i -->\n      <defs>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 54 \nL 9.5 54 \nz\nM 13.59375 65.59375 \nC 16.796875 65.59375 19.203125 67.796875 19.203125 71.296875 \nC 19.203125 74.59375 16.796875 76.796875 13.59375 76.796875 \nC 10.203125 76.796875 7.90625 74.59375 7.90625 71.296875 \nC 7.90625 67.796875 10.203125 65.59375 13.59375 65.59375 \nz\n\" id=\"SourceHanSansSC-Normal-105\"/>\n      </defs>\n      <g transform=\"translate(53.44375 103.922946)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-105\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"176.008527\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- m -->\n      <defs>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 39.5 \nC 22.703125 45.40625 27.5 48.296875 31.703125 48.296875 \nC 39 48.296875 42.296875 43.703125 42.296875 33.296875 \nL 42.296875 0 \nL 50.40625 0 \nL 50.40625 39.5 \nC 55.59375 45.40625 60.203125 48.296875 64.59375 48.296875 \nC 71.796875 48.296875 75.09375 43.703125 75.09375 33.296875 \nL 75.09375 0 \nL 83.296875 0 \nL 83.296875 34.296875 \nC 83.296875 48.09375 77.90625 55.40625 66.90625 55.40625 \nC 60.40625 55.40625 54.703125 51.09375 48.90625 44.90625 \nC 46.796875 51.296875 42.40625 55.40625 34 55.40625 \nC 27.703125 55.40625 21.90625 51.203125 17.203125 46 \nL 16.90625 46 \nL 16.09375 54 \nL 9.5 54 \nz\n\" id=\"SourceHanSansSC-Normal-109\"/>\n      </defs>\n      <g transform=\"translate(44.34375 181.580089)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-109\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"253.66567\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- a -->\n      <g transform=\"translate(49.38375 259.237232)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-97\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"331.322813\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- student -->\n      <defs>\n       <path d=\"M 25.09375 -1.296875 \nC 32.59375 -1.296875 38 2.703125 43.09375 8.59375 \nL 43.40625 8.59375 \nL 44.09375 0 \nL 50.796875 0 \nL 50.796875 54 \nL 42.703125 54 \nL 42.703125 15.296875 \nC 37.296875 8.703125 33.203125 5.796875 27.5 5.796875 \nC 19.90625 5.796875 16.796875 10.40625 16.796875 20.703125 \nL 16.796875 54 \nL 8.703125 54 \nL 8.703125 19.703125 \nC 8.703125 5.90625 13.796875 -1.296875 25.09375 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-117\"/>\n      </defs>\n      <g transform=\"translate(7.2 336.894375)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-115\"/>\n       <use x=\"46.299988\" xlink:href=\"#SourceHanSansSC-Normal-116\"/>\n       <use x=\"83.199982\" xlink:href=\"#SourceHanSansSC-Normal-117\"/>\n       <use x=\"143.399979\" xlink:href=\"#SourceHanSansSC-Normal-100\"/>\n       <use x=\"204.899963\" xlink:href=\"#SourceHanSansSC-Normal-101\"/>\n       <use x=\"259.799957\" xlink:href=\"#SourceHanSansSC-Normal-110\"/>\n       <use x=\"320.299942\" xlink:href=\"#SourceHanSansSC-Normal-116\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"408.979955\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- . -->\n      <defs>\n       <path d=\"M 13.40625 -1.296875 \nC 16.796875 -1.296875 19.59375 1.296875 19.59375 5.09375 \nC 19.59375 9.09375 16.796875 11.703125 13.40625 11.703125 \nC 10.09375 11.703125 7.296875 9.09375 7.296875 5.09375 \nC 7.296875 1.296875 10.09375 -1.296875 13.40625 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-46\"/>\n      </defs>\n      <g transform=\"translate(53.430625 414.551518)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-46\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"486.637098\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- &lt;end&gt; -->\n      <g transform=\"translate(17.07 492.208661)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-60\"/>\n       <use x=\"54.899994\" xlink:href=\"#SourceHanSansSC-Normal-101\"/>\n       <use x=\"109.799988\" xlink:href=\"#SourceHanSansSC-Normal-110\"/>\n       <use x=\"170.299973\" xlink:href=\"#SourceHanSansSC-Normal-100\"/>\n       <use x=\"231.799957\" xlink:href=\"#SourceHanSansSC-Normal-62\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.210625\" xlink:href=\"#m6d6a6195dd\" y=\"564.294241\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 64.210625 603.122813 \nL 64.210625 59.522813 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 607.810625 603.122813 \nL 607.810625 59.522813 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 64.210625 603.122813 \nL 607.810625 603.122813 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 64.210625 59.522812 \nL 607.810625 59.522812 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd6d7e630b6\">\n   <rect height=\"543.6\" width=\"543.6\" x=\"64.210625\" y=\"59.522812\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "translate(u'我是一名学生。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input: <start> 你好 吗 ？ <end>\nPredicted translation: how are you ? <end> \n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"613.822813pt\" version=\"1.1\" viewBox=\"0 0 514.540625 613.822813\" width=\"514.540625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 613.822813 \nL 514.540625 613.822813 \nL 514.540625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 54.340625 603.122813 \nL 507.340625 603.122813 \nL 507.340625 59.522812 \nL 54.340625 59.522812 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p9c62f8612a)\">\n    <image height=\"544\" id=\"image2bf1404448\" transform=\"scale(1 -1)translate(0 -544)\" width=\"453\" x=\"54.340625\" xlink:href=\"data:image/png;base64,\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\" y=\"-59.122813\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3d420e5051\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.640625\" xlink:href=\"#m3d420e5051\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 -3.5 \n\" id=\"me11064cf1f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.640625\" xlink:href=\"#me11064cf1f\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- &lt;start&gt; -->\n      <defs>\n       <path d=\"M 51.09375 15 \nL 51.09375 22.203125 \nL 27 31.203125 \nL 12.09375 36.796875 \nL 12.09375 37.203125 \nL 27 42.90625 \nL 51.09375 51.796875 \nL 51.09375 59 \nL 3.796875 40.40625 \nL 3.796875 33.59375 \nz\n\" id=\"SourceHanSansSC-Normal-60\"/>\n       <path d=\"M 23.296875 -1.296875 \nC 35.796875 -1.296875 42.59375 5.90625 42.59375 14.5 \nC 42.59375 24.796875 33.796875 27.90625 25.90625 31 \nC 19.703125 33.203125 14.09375 35.296875 14.09375 40.703125 \nC 14.09375 45.09375 17.40625 48.90625 24.59375 48.90625 \nC 29.5 48.90625 33.296875 46.796875 37 44.09375 \nL 41 49.40625 \nC 36.90625 52.703125 31.09375 55.40625 24.59375 55.40625 \nC 12.90625 55.40625 6.203125 48.703125 6.203125 40.296875 \nC 6.203125 31.09375 14.5 27.5 22.203125 24.703125 \nC 28.296875 22.5 34.796875 19.90625 34.796875 14.09375 \nC 34.796875 9.09375 31.09375 5.09375 23.59375 5.09375 \nC 16.796875 5.09375 12 7.796875 7.296875 11.59375 \nL 3.203125 6.09375 \nC 8.296875 1.90625 15.59375 -1.296875 23.296875 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-115\"/>\n       <path d=\"M 25.90625 -1.296875 \nC 28.90625 -1.296875 32.5 -0.296875 35.5 0.703125 \nL 33.90625 6.90625 \nC 32.09375 6.09375 29.59375 5.40625 27.59375 5.40625 \nC 21.09375 5.40625 19.09375 9.40625 19.09375 16 \nL 19.09375 47.296875 \nL 34 47.296875 \nL 34 54 \nL 19.09375 54 \nL 19.09375 69.296875 \nL 12.296875 69.296875 \nL 11.296875 54 \nL 2.796875 53.5 \nL 2.796875 47.296875 \nL 11 47.296875 \nL 11 16.296875 \nC 11 5.796875 14.59375 -1.296875 25.90625 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-116\"/>\n       <path d=\"M 21.703125 -1.296875 \nC 28.5 -1.296875 34.703125 2.203125 39.90625 6.59375 \nL 40.203125 6.59375 \nL 40.90625 0 \nL 47.59375 0 \nL 47.59375 33.5 \nC 47.59375 46.5 42.40625 55.40625 29.296875 55.40625 \nC 20.59375 55.40625 13 51.40625 8.296875 48.296875 \nL 11.59375 42.59375 \nC 15.703125 45.5 21.5 48.59375 28 48.59375 \nC 37.296875 48.59375 39.59375 41.40625 39.5 34.09375 \nC 16.296875 31.5 6 25.703125 6 13.90625 \nC 6 4.09375 12.796875 -1.296875 21.703125 -1.296875 \nz\nM 23.90625 5.296875 \nC 18.40625 5.296875 13.90625 7.90625 13.90625 14.40625 \nC 13.90625 21.796875 20.40625 26.40625 39.5 28.59375 \nL 39.5 12.796875 \nC 34 7.90625 29.40625 5.296875 23.90625 5.296875 \nz\n\" id=\"SourceHanSansSC-Normal-97\"/>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 35.203125 \nC 21.296875 44.59375 26.90625 48 31.5 48 \nC 33.59375 48 34.796875 47.703125 36.59375 47.09375 \nL 38.203125 54.203125 \nC 36.40625 55.09375 34.796875 55.40625 32.5 55.40625 \nC 26.40625 55.40625 20.90625 50.90625 17.203125 44.09375 \nL 16.90625 44.09375 \nL 16.09375 54 \nL 9.5 54 \nz\n\" id=\"SourceHanSansSC-Normal-114\"/>\n       <path d=\"M 3.796875 15 \nL 51.09375 33.59375 \nL 51.09375 40.40625 \nL 3.796875 59 \nL 3.796875 51.796875 \nL 27.90625 42.90625 \nL 42.796875 37.203125 \nL 42.796875 36.796875 \nL 27.90625 31.203125 \nL 3.796875 22.203125 \nz\n\" id=\"SourceHanSansSC-Normal-62\"/>\n      </defs>\n      <g transform=\"translate(103.587969 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-60\"/>\n       <use x=\"54.899994\" xlink:href=\"#SourceHanSansSC-Normal-115\"/>\n       <use x=\"101.199982\" xlink:href=\"#SourceHanSansSC-Normal-116\"/>\n       <use x=\"138.099976\" xlink:href=\"#SourceHanSansSC-Normal-97\"/>\n       <use x=\"193.999969\" xlink:href=\"#SourceHanSansSC-Normal-114\"/>\n       <use x=\"231.899963\" xlink:href=\"#SourceHanSansSC-Normal-116\"/>\n       <use x=\"268.799957\" xlink:href=\"#SourceHanSansSC-Normal-62\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.240625\" xlink:href=\"#m3d420e5051\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.240625\" xlink:href=\"#me11064cf1f\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 你好 -->\n      <defs>\n       <path d=\"M 27.09375 83.203125 \nC 21.40625 67.796875 12 52.796875 2 43.09375 \nC 3.296875 41.59375 5.203125 38.203125 5.90625 36.59375 \nC 9.5 40.5 13.203125 45 16.59375 49.90625 \nL 16.59375 -7.40625 \nL 23 -7.40625 \nL 23 59.796875 \nC 27 66.59375 30.5 74 33.40625 81.296875 \nz\nM 45.40625 41.296875 \nC 42.5 29.296875 37.703125 17.296875 31.40625 9.59375 \nC 33 8.703125 35.796875 6.796875 37.09375 5.90625 \nC 43.203125 14.296875 48.59375 26.796875 51.796875 40 \nz\nM 88 57.90625 \nC 87.09375 52.703125 86.09375 47.203125 85.296875 43.5 \nL 90.90625 42.40625 \nC 92.296875 47.59375 94.09375 56.09375 95.296875 63.296875 \nL 90.90625 64.40625 \nL 89.796875 64.09375 \nL 48 64.09375 \nC 50.09375 69.703125 51.796875 75.703125 53.296875 81.59375 \nL 46.796875 83.09375 \nC 43.5 68.296875 38 53.90625 30.5 44.5 \nC 32.09375 43.5 34.703125 41.296875 35.90625 40.296875 \nC 39.40625 45.203125 42.703125 51.09375 45.59375 57.90625 \nL 61.5 57.90625 \nL 61.5 0.703125 \nC 61.5 -0.59375 61.09375 -1 59.796875 -1 \nC 58.5 -1 54.09375 -1.09375 49.296875 -0.90625 \nC 50.296875 -2.90625 51.296875 -5.703125 51.703125 -7.703125 \nC 57.90625 -7.703125 62 -7.5 64.703125 -6.296875 \nC 67.203125 -5.203125 68 -3.203125 68 0.703125 \nL 68 57.90625 \nz\nM 75.90625 40.09375 \nC 81.5 29.5 86.59375 15.40625 88.296875 6.296875 \nL 94.59375 8.40625 \nC 92.90625 17.59375 87.59375 31.40625 81.796875 42 \nz\n\" id=\"SourceHanSansSC-Normal-20320\"/>\n       <path d=\"M 35.296875 56.796875 \nC 33.796875 43.40625 30.59375 32.203125 26.296875 23 \nC 22.5 26.09375 18.40625 29 14.40625 31.59375 \nC 16.40625 38.90625 18.59375 47.703125 20.5 56.796875 \nz\nM 38.203125 63.203125 \nL 37 63 \nL 21.796875 63 \nC 23.203125 69.90625 24.40625 76.90625 25.203125 83.09375 \nL 18.796875 83.5 \nC 18 77.296875 16.796875 70.09375 15.40625 63 \nL 4.5 63 \nL 4.5 56.796875 \nL 14.203125 56.796875 \nC 12 46.40625 9.40625 36.296875 7 29 \nC 12.296875 25.59375 18 21.40625 23.203125 17.09375 \nC 17.796875 8.203125 11 1.796875 3 -2.203125 \nC 4.5 -3.40625 6.40625 -5.796875 7.203125 -7.40625 \nC 15.59375 -2.796875 22.703125 3.703125 28.203125 12.703125 \nC 32.59375 8.796875 36.296875 5 38.796875 1.59375 \nL 43.296875 7.203125 \nC 40.59375 10.703125 36.40625 14.703125 31.59375 18.796875 \nC 37 29.90625 40.59375 44.09375 42.296875 62.203125 \nz\nM 95.5 41.09375 \nL 73.09375 41.09375 \nL 73.09375 51.203125 \nC 80.09375 57.203125 87.40625 65.59375 92.203125 73 \nL 87.59375 76.296875 \nL 86 75.90625 \nL 47.40625 75.90625 \nL 47.40625 69.796875 \nL 81.40625 69.796875 \nC 77.40625 63.90625 71.59375 57.203125 66.296875 52.90625 \nL 66.296875 41.09375 \nL 42.796875 41.09375 \nL 42.796875 34.796875 \nL 66.296875 34.796875 \nL 66.296875 0.59375 \nC 66.296875 -0.796875 65.796875 -1.296875 64.09375 -1.40625 \nC 62.59375 -1.40625 57.203125 -1.40625 51.09375 -1.296875 \nC 52.09375 -3.09375 53.296875 -5.796875 53.703125 -7.59375 \nC 61.40625 -7.703125 66 -7.5 69 -6.5 \nC 72 -5.40625 73.09375 -3.5 73.09375 0.59375 \nL 73.09375 34.796875 \nL 95.5 34.796875 \nz\n\" id=\"SourceHanSansSC-Normal-22909\"/>\n      </defs>\n      <g transform=\"translate(194.187969 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-20320\"/>\n       <use x=\"99.999985\" xlink:href=\"#SourceHanSansSC-Normal-22909\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"280.840625\" xlink:href=\"#m3d420e5051\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"280.840625\" xlink:href=\"#me11064cf1f\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 吗 -->\n      <defs>\n       <path d=\"M 27.40625 67.796875 \nL 27.40625 25.09375 \nL 14 25.09375 \nL 14 67.796875 \nz\nM 33.40625 73.90625 \nL 7.90625 73.90625 \nL 7.90625 9.296875 \nL 14 9.296875 \nL 14 18.90625 \nL 33.40625 18.90625 \nz\nM 78.90625 20.40625 \nL 38.296875 20.40625 \nL 38.296875 14.296875 \nL 78.90625 14.296875 \nz\nM 81 39.90625 \nC 82.5 52.09375 84.203125 67.09375 85 77.296875 \nL 80.296875 77.796875 \nL 79.203125 77.5 \nL 41.90625 77.5 \nL 41.90625 71.40625 \nL 78.09375 71.40625 \nC 77.296875 62.703125 76 50.09375 74.703125 39.90625 \nL 50.296875 39.90625 \nC 51.296875 47.296875 52.296875 56.703125 52.796875 64.296875 \nL 46.703125 64.703125 \nC 46 55.203125 44.59375 42.09375 43.40625 34.09375 \nL 45.09375 34.09375 \nL 45.09375 34 \nL 86.796875 34 \nC 84.796875 11.59375 82.5 2.5 79.90625 -0.09375 \nC 78.90625 -1.09375 77.796875 -1.296875 76.09375 -1.203125 \nC 74.296875 -1.203125 69.703125 -1.203125 64.796875 -0.703125 \nC 65.90625 -2.40625 66.5 -4.90625 66.703125 -6.796875 \nC 71.5 -7.09375 76 -7.09375 78.5 -6.90625 \nC 81.5 -6.796875 83.296875 -6.09375 85.203125 -4.09375 \nC 88.703125 -0.5 91 9.796875 93.296875 36.796875 \nC 93.40625 37.703125 93.5 39.90625 93.5 39.90625 \nz\n\" id=\"SourceHanSansSC-Normal-21527\"/>\n      </defs>\n      <g transform=\"translate(284.787969 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-21527\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"371.440625\" xlink:href=\"#m3d420e5051\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"371.440625\" xlink:href=\"#me11064cf1f\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- ？ -->\n      <defs>\n       <path d=\"M 19.90625 23.90625 \nL 27.203125 23.90625 \nC 24.40625 39.203125 46 42.59375 46 58 \nC 46 68.90625 38.203125 76.09375 25.796875 76.09375 \nC 16.09375 76.09375 9.5 71.59375 3.296875 65.296875 \nL 8.203125 60.796875 \nC 13.5 66.40625 19 69.40625 25 69.40625 \nC 33.90625 69.40625 37.90625 64.09375 37.90625 57.296875 \nC 37.90625 45.59375 16.59375 40.796875 19.90625 23.90625 \nz\nM 23.703125 -0.40625 \nC 27 -0.40625 29.703125 1.90625 29.703125 5.703125 \nC 29.703125 9.5 27 12.09375 23.703125 12.09375 \nC 20.5 12.09375 17.703125 9.5 17.703125 5.703125 \nC 17.703125 1.90625 20.40625 -0.40625 23.703125 -0.40625 \nz\n\" id=\"SourceHanSansSC-Normal-65311\"/>\n      </defs>\n      <g transform=\"translate(375.387969 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-65311\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"462.040625\" xlink:href=\"#m3d420e5051\" y=\"603.122813\"/>\n      </g>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"462.040625\" xlink:href=\"#me11064cf1f\" y=\"59.522812\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- &lt;end&gt; -->\n      <defs>\n       <path d=\"M 30.90625 -1.296875 \nC 38.40625 -1.296875 43.90625 1.203125 48.59375 4.203125 \nL 45.59375 9.59375 \nC 41.59375 6.90625 37.203125 5.203125 31.90625 5.203125 \nC 21.09375 5.203125 13.90625 13.203125 13.40625 25.203125 \nL 50.296875 25.203125 \nC 50.59375 26.5 50.703125 28.296875 50.703125 30.09375 \nC 50.703125 45.703125 42.90625 55.40625 29.40625 55.40625 \nC 17 55.40625 5.296875 44.5 5.296875 27 \nC 5.296875 9.203125 16.703125 -1.296875 30.90625 -1.296875 \nz\nM 13.296875 31.203125 \nC 14.40625 42.296875 21.5 48.796875 29.5 48.796875 \nC 38.296875 48.796875 43.5 42.703125 43.5 31.203125 \nz\n\" id=\"SourceHanSansSC-Normal-101\"/>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 39.5 \nC 23.203125 45.296875 27.296875 48.296875 33 48.296875 \nC 40.5 48.296875 43.703125 43.703125 43.703125 33.296875 \nL 43.703125 0 \nL 51.90625 0 \nL 51.90625 34.296875 \nC 51.90625 48.09375 46.703125 55.40625 35.40625 55.40625 \nC 28 55.40625 22.40625 51.203125 17.203125 46.09375 \nL 16.90625 46.09375 \nL 16.09375 54 \nL 9.5 54 \nz\n\" id=\"SourceHanSansSC-Normal-110\"/>\n       <path d=\"M 27.703125 -1.296875 \nC 34.296875 -1.296875 40.09375 2.203125 44.40625 6.5 \nL 44.703125 6.5 \nL 45.40625 0 \nL 52.09375 0 \nL 52.09375 79.59375 \nL 44 79.59375 \nL 44 58.40625 \nL 44.40625 49 \nC 39.5 53 35.296875 55.40625 28.90625 55.40625 \nC 16.5 55.40625 5.40625 44.40625 5.40625 27 \nC 5.40625 8.90625 14.09375 -1.296875 27.703125 -1.296875 \nz\nM 29.40625 5.59375 \nC 19.5 5.59375 13.90625 13.703125 13.90625 27 \nC 13.90625 39.59375 21 48.5 30.203125 48.5 \nC 34.90625 48.5 39.09375 46.796875 44 42.5 \nL 44 13.296875 \nC 39.203125 8.203125 34.59375 5.59375 29.40625 5.59375 \nz\n\" id=\"SourceHanSansSC-Normal-100\"/>\n      </defs>\n      <g transform=\"translate(465.987969 52.522812)rotate(-90)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-60\"/>\n       <use x=\"54.899994\" xlink:href=\"#SourceHanSansSC-Normal-101\"/>\n       <use x=\"109.799988\" xlink:href=\"#SourceHanSansSC-Normal-110\"/>\n       <use x=\"170.299973\" xlink:href=\"#SourceHanSansSC-Normal-100\"/>\n       <use x=\"231.799957\" xlink:href=\"#SourceHanSansSC-Normal-62\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1947566466\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.340625\" xlink:href=\"#m1947566466\" y=\"104.822813\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- how -->\n      <defs>\n       <path d=\"M 9.5 0 \nL 17.59375 0 \nL 17.59375 39.5 \nC 23.203125 45.296875 27.296875 48.296875 33 48.296875 \nC 40.5 48.296875 43.703125 43.703125 43.703125 33.296875 \nL 43.703125 0 \nL 51.90625 0 \nL 51.90625 34.296875 \nC 51.90625 48.09375 46.703125 55.40625 35.40625 55.40625 \nC 28 55.40625 22.5 51.203125 17.296875 46.203125 \nL 17.59375 57.5 \nL 17.59375 79.59375 \nL 9.5 79.59375 \nz\n\" id=\"SourceHanSansSC-Normal-104\"/>\n       <path d=\"M 30.09375 -1.296875 \nC 43.296875 -1.296875 55 9.09375 55 27 \nC 55 45 43.296875 55.40625 30.09375 55.40625 \nC 16.90625 55.40625 5.296875 45 5.296875 27 \nC 5.296875 9.09375 16.90625 -1.296875 30.09375 -1.296875 \nz\nM 30.09375 5.5 \nC 20.40625 5.5 13.703125 14.09375 13.703125 27 \nC 13.703125 39.796875 20.40625 48.5 30.09375 48.5 \nC 39.796875 48.5 46.59375 39.796875 46.59375 27 \nC 46.59375 14.09375 39.796875 5.5 30.09375 5.5 \nz\n\" id=\"SourceHanSansSC-Normal-111\"/>\n       <path d=\"M 17.90625 0 \nL 27.5 0 \nL 35.40625 30 \nC 37 35.09375 38.09375 40.203125 39.296875 45.703125 \nL 39.796875 45.703125 \nC 41.09375 40.203125 42.09375 35.296875 43.59375 30.09375 \nL 51.796875 0 \nL 61.703125 0 \nL 76.5 54 \nL 68.703125 54 \nL 60.40625 21.90625 \nC 59.203125 16.796875 58.09375 12 56.90625 7 \nL 56.5 7 \nC 55.203125 12 54 16.796875 52.703125 21.90625 \nL 43.90625 54 \nL 35.703125 54 \nL 27 21.90625 \nC 25.59375 16.796875 24.5 12 23.203125 7 \nL 22.796875 7 \nC 21.703125 12 20.703125 16.796875 19.5 21.90625 \nL 11 54 \nL 2.703125 54 \nz\n\" id=\"SourceHanSansSC-Normal-119\"/>\n      </defs>\n      <g transform=\"translate(19.410625 110.394375)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-104\"/>\n       <use x=\"60.199997\" xlink:href=\"#SourceHanSansSC-Normal-111\"/>\n       <use x=\"120.399994\" xlink:href=\"#SourceHanSansSC-Normal-119\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.340625\" xlink:href=\"#m1947566466\" y=\"195.422813\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- are -->\n      <g transform=\"translate(26.52 200.994375)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-97\"/>\n       <use x=\"55.899994\" xlink:href=\"#SourceHanSansSC-Normal-114\"/>\n       <use x=\"93.799988\" xlink:href=\"#SourceHanSansSC-Normal-101\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.340625\" xlink:href=\"#m1947566466\" y=\"286.022813\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- you -->\n      <defs>\n       <path d=\"M 9.59375 -23.59375 \nC 20.09375 -23.59375 25.703125 -15.296875 29.296875 -5 \nL 49.90625 54 \nL 41.90625 54 \nL 31.796875 23.09375 \nC 30.296875 18.40625 28.703125 12.796875 27.203125 7.90625 \nL 26.703125 7.90625 \nC 24.90625 12.796875 23 18.40625 21.296875 23.09375 \nL 9.796875 54 \nL 1.296875 54 \nL 23.09375 -0.296875 \nL 21.90625 -4.5 \nC 19.5 -11.5 15.5 -16.703125 9.296875 -16.703125 \nC 7.796875 -16.703125 6.203125 -16.296875 5.09375 -15.90625 \nL 3.40625 -22.5 \nC 5.09375 -23.203125 7.203125 -23.59375 9.59375 -23.59375 \nz\n\" id=\"SourceHanSansSC-Normal-121\"/>\n       <path d=\"M 25.09375 -1.296875 \nC 32.59375 -1.296875 38 2.703125 43.09375 8.59375 \nL 43.40625 8.59375 \nL 44.09375 0 \nL 50.796875 0 \nL 50.796875 54 \nL 42.703125 54 \nL 42.703125 15.296875 \nC 37.296875 8.703125 33.203125 5.796875 27.5 5.796875 \nC 19.90625 5.796875 16.796875 10.40625 16.796875 20.703125 \nL 16.796875 54 \nL 8.703125 54 \nL 8.703125 19.703125 \nC 8.703125 5.90625 13.796875 -1.296875 25.09375 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-117\"/>\n      </defs>\n      <g transform=\"translate(23.315313 291.567031)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-121\"/>\n       <use x=\"51.199997\" xlink:href=\"#SourceHanSansSC-Normal-111\"/>\n       <use x=\"111.399994\" xlink:href=\"#SourceHanSansSC-Normal-117\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.340625\" xlink:href=\"#m1947566466\" y=\"376.622813\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- ? -->\n      <defs>\n       <path d=\"M 17.90625 21.59375 \nL 25.09375 21.59375 \nC 23.203125 37.5 41.296875 43.59375 41.296875 58.40625 \nC 41.296875 69 34.203125 76 23 76 \nC 15 76 8.796875 72.09375 4.203125 67 \nL 8.90625 62.703125 \nC 12.40625 66.703125 17.09375 69.203125 22.09375 69.203125 \nC 29.59375 69.203125 33.296875 64 33.296875 57.90625 \nC 33.296875 45.59375 15.5 39.203125 17.90625 21.59375 \nz\nM 21.796875 -1.296875 \nC 25.09375 -1.296875 27.90625 1.296875 27.90625 5.09375 \nC 27.90625 9.09375 25.09375 11.703125 21.796875 11.703125 \nC 18.40625 11.703125 15.59375 9.09375 15.59375 5.09375 \nC 15.59375 1.296875 18.40625 -1.296875 21.796875 -1.296875 \nz\n\" id=\"SourceHanSansSC-Normal-63\"/>\n      </defs>\n      <g transform=\"translate(40.802188 382.194375)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-63\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.340625\" xlink:href=\"#m1947566466\" y=\"467.222813\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- &lt;end&gt; -->\n      <g transform=\"translate(7.2 472.794375)scale(0.14 -0.14)\">\n       <use xlink:href=\"#SourceHanSansSC-Normal-60\"/>\n       <use x=\"54.899994\" xlink:href=\"#SourceHanSansSC-Normal-101\"/>\n       <use x=\"109.799988\" xlink:href=\"#SourceHanSansSC-Normal-110\"/>\n       <use x=\"170.299973\" xlink:href=\"#SourceHanSansSC-Normal-100\"/>\n       <use x=\"231.799957\" xlink:href=\"#SourceHanSansSC-Normal-62\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.340625\" xlink:href=\"#m1947566466\" y=\"557.822813\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 54.340625 603.122813 \nL 54.340625 59.522813 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 507.340625 603.122813 \nL 507.340625 59.522813 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 54.340625 603.122813 \nL 507.340625 603.122813 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 54.340625 59.522812 \nL 507.340625 59.522812 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9c62f8612a\">\n   <rect height=\"543.6\" width=\"453\" x=\"54.340625\" y=\"59.522812\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "translate(u'你好吗？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def load_tensor(filename):\n",
    "    return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_test = load_tensor('input_tensor_test.pkl')\n",
    "target_tensor_test = load_tensor('target_tensor_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_sentense(tensor, token):\n",
    "    sentense = ''\n",
    "    for t in range(len(tensor)):\n",
    "        id = tensor[t]\n",
    "        sentense += token.index_word[id] + ' '\n",
    "        if token.index_word[id] == '<end>':\n",
    "            return sentense\n",
    "\n",
    "    return sentense\n",
    "\n",
    "def predict_sentense(inputs):\n",
    "    inputs = tf.expand_dims(inputs, axis=0)\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result\n",
    "\n",
    "        # 预测的 ID 被输送回模型\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "输入中文  <start> 看 外面 正在 发生 什么 。 <end> \n实际英文  <start> look at what s happening outside . <end> \n预测英文  look , what happened . <end> \n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4415"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "print('输入中文 ', tensor_sentense(input_tensor_test[3], inp_lang))\n",
    "print('实际英文 ', tensor_sentense(target_tensor_test[3], targ_lang))\n",
    "print('预测英文 ', predict_sentense(input_tensor_test[3]))\n",
    "len(input_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "输入中文=[ 汤姆 的 教室 在 哪里 ？  ], 实际英文=[ where is tom s classroom ?  ], 预测英文=[where s the nearest telephone booth ?  ]\n输入中文=[ 汤姆 不 知道 玛丽 有 男朋友 。  ], 实际英文=[ tom didn t know mary had a boyfriend .  ], 预测英文=[tom doesn t know if mary has a boyfriend .  ]\n输入中文=[ 请 坐在 沙发 上放 轻松 。  ], 实际英文=[ please sit on the sofa and relax .  ], 预测英文=[please be postponed from the dark .  ]\n输入中文=[ 看 外面 正在 发生 什么 。  ], 实际英文=[ look at what s happening outside .  ], 预测英文=[look , what happened .  ]\n输入中文=[ 他 这个 时候 该 到 了 。  ], 实际英文=[ this is the time he normally arrives .  ], 预测英文=[he should be coming to bed .  ]\n输入中文=[ 我们 几乎 像 兄弟 一样 。  ], 实际英文=[ we re almost like brothers .  ], 预测英文=[we almost love brothers .  ]\n输入中文=[ 汤姆 不 知道 玛丽 住 在 哪里 。  ], 实际英文=[ tom doesn t know where mary lives .  ], 预测英文=[tom doesn t know where mary lives .  ]\n输入中文=[ 你 想 跟 我 去 野餐 吗 ？  ], 实际英文=[ do you want to go on a picnic with me ?  ], 预测英文=[would you going to go to the picnic with me ?  ]\n输入中文=[ 他会 成为 一个 好 的 医生 的 。  ], 实际英文=[ he will be a good doctor .  ], 预测英文=[he will make a good driver .  ]\n输入中文=[ 他 供认 了 杀人 的 罪行 。  ], 实际英文=[ he confessed to the murder .  ], 预测英文=[he got a strong as short of his autobiography .  ]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8150\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8151\u001b[0;31m         tld.op_callbacks, tensor, shape)\n\u001b[0m\u001b[1;32m   8152\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-eda23234f5c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mraw_chn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_sentense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mraw_eng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_sentense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mraw_chn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_chn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<end>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mraw_eng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_eng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<end>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-6f800ba9e9d4>\u001b[0m in \u001b[0;36mpredict_sentense\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         predictions, dec_hidden, attention_weights = decoder(dec_input,\n\u001b[1;32m     23\u001b[0m                                                              \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                                              enc_out)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpredicted_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    977\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-54d77ececf24>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    977\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-dd9fd3606e9a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, values)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     score = self.V(tf.nn.tanh(\n\u001b[0;32m---> 18\u001b[0;31m         self.W1(values) + self.W2(hidden_with_time_axis)))\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    977\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m       \u001b[0;31m# Broadcasting is required for the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4481\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4482\u001b[0m         return array_ops.reshape(\n\u001b[0;32m-> 4483\u001b[0;31m             ab_matmul, a_free_dims + b_free_dims, name=name)\n\u001b[0m\u001b[1;32m   4484\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4485\u001b[0m       \u001b[0ma_free_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8149\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   8150\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8151\u001b[0;31m         tld.op_callbacks, tensor, shape)\n\u001b[0m\u001b[1;32m   8152\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8153\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actual, predicted = list(), list()\n",
    "for i in range(len(input_tensor_test)):\n",
    "\traw_chn = tensor_sentense(input_tensor_test[i], inp_lang)\n",
    "\traw_eng = tensor_sentense(target_tensor_test[i], targ_lang)\n",
    "\ttranslation = predict_sentense(input_tensor_test[i])\n",
    "\traw_chn = raw_chn.replace('<start>','').replace('<end>','')\n",
    "\traw_eng = raw_eng.replace('<start>','').replace('<end>','')\n",
    "\ttranslation = translation.replace('<start>','').replace('<end>','')\n",
    "\tif i < 10:\n",
    "\t\tprint('输入中文=[%s], 实际英文=[%s], 预测英文=[%s]' % (raw_chn, raw_eng, translation))\n",
    "\tactual.append([raw_eng.split()])\n",
    "\tpredicted.append(translation.split())\n",
    "\n",
    "print(actual[0:2])\n",
    "print(predicted[0:2])\n",
    "# calculate BLEU score\n",
    "print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.33, 0.33, 0.33, 0)))\n",
    "print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 20\n",
    "BLEU-1: 0.550518\n",
    "BLEU-2: 0.392867\n",
    "BLEU-3: 0.302809\n",
    "BLEU-4: 0.233100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'rouge-1': {'f': 0.4615384565680473, 'p': 0.42857142857142855, 'r': 0.5}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.4615384565680473, 'p': 0.42857142857142855, 'r': 0.5}}\nMETEOR: 0.24590163934426232\n"
    }
   ],
   "source": [
    "hypothesis = 'where s the nearest telephone booth ?'\n",
    "reference = 'where is tom s classroom ?' \n",
    "\n",
    "rouge = Rouge()\n",
    "print(rouge.get_scores(hypothesis, reference, avg=True))\n",
    "print('METEOR:', single_meteor_score(reference,hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "输入中文=[汤姆 的 教室 在 哪里 ？], 实际英文=[where is tom s classroom ?], 预测英文=[where s the nearest telephone booth ?]\n输入中文=[汤姆 不 知道 玛丽 有 男朋友 。], 实际英文=[tom didn t know mary had a boyfriend .], 预测英文=[tom doesn t know if mary has a boyfriend .]\n输入中文=[请 坐在 沙发 上放 轻松 。], 实际英文=[please sit on the sofa and relax .], 预测英文=[please be postponed from the dark .]\n输入中文=[看 外面 正在 发生 什么 。], 实际英文=[look at what s happening outside .], 预测英文=[look , what happened .]\n输入中文=[他 这个 时候 该 到 了 。], 实际英文=[this is the time he normally arrives .], 预测英文=[he should be coming to bed .]\n输入中文=[我们 几乎 像 兄弟 一样 。], 实际英文=[we re almost like brothers .], 预测英文=[we almost love brothers .]\n输入中文=[汤姆 不 知道 玛丽 住 在 哪里 。], 实际英文=[tom doesn t know where mary lives .], 预测英文=[tom doesn t know where mary lives .]\n输入中文=[你 想 跟 我 去 野餐 吗 ？], 实际英文=[do you want to go on a picnic with me ?], 预测英文=[would you going to go to the picnic with me ?]\n输入中文=[他会 成为 一个 好 的 医生 的 。], 实际英文=[he will be a good doctor .], 预测英文=[he will make a good driver .]\n输入中文=[他 供认 了 杀人 的 罪行 。], 实际英文=[he confessed to the murder .], 预测英文=[he got a strong as short of his autobiography .]\n['where is tom s classroom ?', 'tom didn t know mary had a boyfriend .']\n['where s the nearest telephone booth ?', 'tom doesn t know if mary has a boyfriend .']\n{'rouge-1': {'f': 0.5178593884949952, 'p': 0.5326023840270103, 'r': 0.5185645882069546}, 'rouge-2': {'f': 0.283772277567112, 'p': 0.2916948885279044, 'r': 0.28456496503168494}, 'rouge-l': {'f': 0.51759913638108, 'p': 0.538642602576883, 'r': 0.5101709789224532}}\n"
    }
   ],
   "source": [
    "actual, predicted = list(), list()\n",
    "for i in range(len(input_tensor_test)):\n",
    "\traw_chn = tensor_sentense(input_tensor_test[i], inp_lang)\n",
    "\traw_eng = tensor_sentense(target_tensor_test[i], targ_lang)\n",
    "\ttranslation = predict_sentense(input_tensor_test[i])\n",
    "\traw_chn = raw_chn.replace('<start>','').replace('<end>','').strip().rstrip()\n",
    "\traw_eng = raw_eng.replace('<start>','').replace('<end>','').strip().rstrip()\n",
    "\ttranslation = translation.replace('<start>','').replace('<end>','').strip().rstrip()\n",
    "\tif i < 10:\n",
    "\t\tprint('输入中文=[%s], 实际英文=[%s], 预测英文=[%s]' % (raw_chn, raw_eng, translation))\n",
    "\tactual.append(raw_eng)\n",
    "\tpredicted.append(translation)\n",
    "\n",
    "print(actual[0:2])\n",
    "print(predicted[0:2])\n",
    "# calculate Rouge score\n",
    "rouge = Rouge()\n",
    "print(rouge.get_scores(predicted, actual, avg=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'rouge-1': {'f': 0.5178593884949952, 'p': 0.5326023840270103, 'r': 0.5185645882069546}, 'rouge-2': {'f': 0.283772277567112, 'p': 0.2916948885279044, 'r': 0.28456496503168494}, 'rouge-l': {'f': 0.51759913638108, 'p': 0.538642602576883, 'r': 0.5101709789224532}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "where s the nearest telephone booth ?\nwhere is tom s classroom ?\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.24590163934426232"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "hypothesis = predicted[0]\n",
    "reference = actual[0]\n",
    "print(hypothesis)\n",
    "print(reference)\n",
    "single_meteor_score(reference,hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5083032737375731\n"
    }
   ],
   "source": [
    "total_score = 0\n",
    "\n",
    "for i in range(len(input_tensor_test)):\n",
    "    hypothesis = predicted[i]\n",
    "    reference = actual[i]\n",
    "    total_score += single_meteor_score(reference,hypothesis)\n",
    "print(total_score / len(input_tensor_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}